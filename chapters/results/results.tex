\chapter{Experimental setup and design}

In this chapter we describe the semi-supervised classification and clustering results obtained on the three AT-TPC (active target time projection chamber) datasets described in section \ref{sec:data}. The simulated data is used to provide a benchmark for the upper bound on the performance of a given algorithm. This chapter is structured by task first, and algorithm second. As such we will begin with a consideration of the semi-supervised algorithms before continuing with the clustering task. 

 We explore the models proposed in chapter \ref{ch:autoencoder} on two disparate tasks, one of semi-supervised classification and one of clustering. For each task  we evaluate the performance on each of the aforementioned datasets using appropriate metrics, which were introduced in section \ref{sec:performance_val}. 

 The primary objective for the ${}^{46}Ar$ experiment was to identify resonant proton scattering events, but this thesis explores broader applications than this classification task. This broader picture is specifically geared the application of the models discussed in this thesis to other AT-TPC experiments. Following this argument we measure individual class performance wherever appropriate. 

The machine learning experiments conducted in this thesis were performed using the AI-Hub computational cluster at the university of Oslo.  This resource consists of three machines with four RTX $2080$ Nvidia GPU's (graphics processing unit) each. These cards have $\sim 10$GB of memory available for the allocation of models.

\subsection{Semi-supervised classification procedure}

The semi-supervised task is to train an autoencoder model on a large dataset, and evaluate the class separation of the latent space using a logistic regression classifier. We use a logistic regression classifier as we wish to measure qualities of the latent space, and not of the classification per se. To provide an additional benchmark for our algorithms we measure the performance of a logistic regression classifier using the latent space of a pre-trained image classifier model, which has shown to be effective in the classification of events from the ${}^{46}Ar$ experiment (\cite{Kuchera2019}).

Intrinsic to the measurement of the semi-supervised performance is the budgeting of how many labeled samples one can feasibly extract. And the principal limitation of the semi-supervised approach is the assumption that the researchers are able to positively identify the event class(es) of interest. It is then interesting to quantify the change in model performance as a function of how many labeled samples the classification model has to train on. Bear in mind that the representation that the classification model sees is still trained on the full set of events for a given dataset. 

For reference, the models are described in terms of their hyperparameters in table \ref{tab:convae_hyperparams} for the convolutional autoencoder and table \ref{tab:draw_hyperparams} for the DRAW-analogues. To determine the best hyperparameters we perform on the order of $\sim 10^2$ runs, each taking on the order of $\sim 10^1$ minutes on a single Nvidia $2080$ GPU. For each configuration of the algorithms we train a classifier trained on a subset of the labeled set, and evaluated on the remainder to estimate the OOS (out of sample) error. The best configuration is then lastly re-trained, and we evaluate the OOS error with k-fold cross validation as outlined in section \ref{sec:performance_val}.

\subsection{Clustering procedure}

In contrast to the semi-supervised task the clustering objective presumes that we have access to no labeled data. But since the purpose of this thesis is in large part exploratory we will measure performance on the labeled data provided. We explore performance of the deep clustering algorithms described in section \ref{sec:deep_clustering} as well as a K-means approach using the latent space of a pre-trained image classifier model. 

The clustering task is intrinsically a harder task than that of semi-supervised classification, and so more time was spent exploring algorithms to determine which were suitable for clustering AT-TPC data. Before training each of the algorithms in section \ref{sec:deep_clustering} were first configured to reproduce the results from their respective papers. Subsequently they were applied to the AT-TPC data, with their autoencoder hyperparameters selected empirically from the semi-supervised task. This was done so as to enable a focus on the clustering components of the algorithm. In particular we focus on the weighting parameters of the MIXAE (mixture of autoencoders) clustering algorithm.
