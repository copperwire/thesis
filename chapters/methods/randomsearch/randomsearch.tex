\section{Hyperparameter search architecture}\label{sec:hyperparam_search_arch}

To tune the hyperparameters of the sequential and non sequential autoencoders we implement an object oriented searching framework. A parent class \lstinline{ModelGenerator} defines the logging variables and the type of model to be generated, i.e. one of \lstinline{ConVAE} or \lstinline{DRAW}. As well as helper functions to log performance metrics and loss values. The \lstinline{ModelGenerator} class is treated as an abstract class in that it should never be instantiated on it's own, only through its children. One subclass is implemented for the \lstinline{ConVAE} and \lstinline{DRAW} model classes. They share common functionality and maintain a grid over all the search able hyperparameters which we sample from to perform the search.

Searching can be done with a select sub-set of variables by specifying the \lstinline{static} flag to the model-creator. This flag locks some parameters to pre-selected values and searches over the others. For the convolutional autoencoder the \lstinline{static} flag holds the convolutional architecture, i.e. kernel sizes stride size and number of layers constant while the sequential DRAW model specifies a convolutional architecture as well as parameters for the read-write paired functions. Other flags are \lstinline{ours} for a very wide search and \lstinline{vgg} for a VGG16 like architecture. \todo{implement static for draw}

Searching, saving to file and other utilities are maintained in the \lstinline{RandomSearch} class which is instantiated with one of the \lstinline{ModelGenerator} subclasses and implements a \lstinline{.search} method which performs and logs the search to a specified directory. 