\chapter{Introduction}\label{ch:introduction}

\begin{itemize}
\item Modern nuclear physics - rare events - detectors with high efficiency - loads of data 
\item Traditional methods of fitting are expensive, and have a problematic bias 
\item Machine learning allows a different approach
\item Promise of discovery from unsupervised methods 
\item Need for exploration 
\end{itemize}

In this thesis we address a long standing challenge in modern nuclear physics. 
The necessary efficiency of the detectors used in the analysis of rare nuclides means that much of the collected data is not pertinent to the questions we ask. One way of filtering out these unwanted events is to use machine learning algorithms. Machine learning is a field of study with elements from mathematics and computer science that deals in pattern recognition and function approximation. In this thesis we explore the application of a set of such algorithms to the segmentation of events from a rare isotope detector.

Nuclear physics is the pursuit of understanding nuclides, which are the building blocks of the visible universe. These building blocks are made up of protons and neutrons. But while most matter we interact with is stable, the vast majority of the hitherto discovered nuclides are not. However, understanding these unstable nuclides are important to our understanding of the universe, as well as having implications in medicine and the industry. Detecting these rare nuclides require very sensitive, and specialized, equipment. One such piece of equipment is the AT-TPC (active target time-projection chamber) detector. When running it can detect on the order of $10^4$ events each hour, producing terabytes of data each day it is active. In this thesis we work with data from an AT-TPC detector constructed and commissioned at the National Cyclotron Laboratory located on the Michigan State University campus. 

The two main topics we address in this thesis is how many events from known reactions do we need to construct a good model, and given the absence of known reactions can we segment events by reaction type. 

\section{Machine learning}

In modern science, data analysis has become ubiquitous. For many applications it is now possible to collect data with samples numbering from several thousands to billions, which has transformed the modeling needs in those sciences. Machine learning is closely tied to this development. Machine learning models tend to have a large number of degrees of freedom, which means they need large volumes of data to perform well. These models have for example been used to beat human professionals in chess and go\footnote{Go is a strategy game played on a grid, and is like chess in that it rewards long-term planning.} from just knowing the rules of the game (\cite{Silver2017}), they also fundamentally affect our on-line interactions\footnote{\href{https://research.fb.com/category/machine-learning/}{Facebook} invests heavily in machine learning research, and apply insights from this research to dictate what we view and interact with on their platforms.}. However, machine learning models also include familiar methods like ordinary least squares regression. 

At the heart of modern machine learning is the Artificial Neural Network family of algorithms. These models, which are based on systems of biological neurons, have shown themselves to be very good at approximating complex functions (\cite{Lin2017}). They are also fundamentally flexible algorithms, and can be applied to image analysis, time-series prediction or regression tasks with relative ease.

In this thesis we will consider a special property of Neural Networks. We know that they can achieve a high degree of compression of complex input, and that these compressions can be inform us of important differences in the input space. We consider the space of nuclear reactions in an experiment in this thesis, and apply methods that are able to discover structure without being explicitly informed what to look for.

\section{Why machine learning?}

Traditionally, data from experiments recorded with an AT-TPC is analyzed with a Monte Carlo method. In this framework each event is treated as a potential candidate for the reaction of interest, and a number of physical parameters are tested to find the best fit for that event. Once this is performed for all events in the dataset, a threshold value for the fit-statistic is chosen. Events that are below this threshold value are then said to be events of interest, and the rest are discarded. Some of the events of interest are bound to be discarded with this method, which is problematic when the interesting reactions are rare. 

This method of analysis turns out to be very computationally costly. Additionally, the presumption that each event is considered a possible candidate for the reaction of interest can be problematic. In the case where the breadth of possible reactions is not known, fitting against the reaction of interest can give unexpected results. Lastly, the fitting method requires that the records are of complete tracks, but this is not always the case.

In this thesis we then propose computationally feasible models, that do not explicitly fit against the reaction of interest, and who are agnostic to the completeness of the tracks, from the machine learning literature.

\section{Ethical considerations}

Reproducibility is a cornerstone of the scientific process, and in computational science version control systems like \href{https://github.com/}{Github} make it possible to track development as well as providing opportunities for other researchers to easily reproduce results. To further this standard of research we make code from this thesis available for any to access from our \href{https://github.com/ATTPC/VAE-event-classification}{repository.} 

In addition to being applied in quantum and statistical mechanics, and the design of robots with robust movement abilities\footnote{Boston dynamics design and manufacture \href{https://www.youtube.com/watch?v=LikxFZZO2sk}{robots} with exceptional adaptability to varying environments}, machine learning can also be applied to the detection of sexual orientation from facial images (\citet{Wang2018}). As LGBTQ persons are still persecuted in many nations, this has the potential to influence these persons livelihood, as well as their mental and physical health. The algorithms developed for this thesis are latent variable models for the segmentation of data, and it is easy to transfer these algorithms to different arenas in e.g. the segmentation of people in discrete groups.

It is difficult to say what moral obligations is carried by the researcher in this instance. But it is not unfamiliar territory, as the development of nuclear weaponry is closely tied with the emergence of modern nuclear theory. From this history we can infer that the openness of the scientific discourse is a necessary ingredient in providing strategies for dealing with complex issues such as these. That is not to say that this discourse is sufficient, and being critical of our role as researchers in the development of these algorithms is important. Additionally, we must engage with society and lawmakers on these issues, as part of the responsibility of being a scientist. 

\section{Structure of the thesis}

As machine learning is still nascent in its application to nuclear physics we begin with a thorough introduction to the theory in the first chapter of part I. We continue in the second chapter with an introduction to the models implemented and applied in this thesis. The last chapter of part I is devoted to elaborating on the experiment, and data, that forms the basis for our analysis.

Part II is devoted to the details of the implementation. We've chosen the \lstinline{Python} programming language as the basis for the implementation because of the mature machine learning libraries developed for the language. 

Lastly, in parts III and IV we present our findings and discuss those. We also present avenues for further research based on our findings.
